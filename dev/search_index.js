var documenterSearchIndex = {"docs":
[{"location":"indices/#Index","page":"Indices","title":"Index","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"","category":"page"},{"location":"indices/","page":"Indices","title":"Indices","text":"Modules = [ExpectationMaximizationPCA]","category":"page"},{"location":"indices/#ExpectationMaximizationPCA.EMPCA!-Tuple{AbstractMatrix{T} where T, AbstractMatrix{T} where T, AbstractVector{T} where T, AbstractMatrix{T} where T, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA.EMPCA!","text":"EMPCA!(basis_vecs, scores, μ, data_tmp, weights; use_log, kwargs...)\n\nPerforms in-place (modifying basis_vecs, scores, and data_tmp) expectation-maximization principal component analysis (EMPCA) on data_tmp using weights as the weights.\n\nKeyword Arguments\n\nuse_log::false: whether you want to perform EMPCA on the log of data instead\ninds::AbstractUnitRange=axes(basis_vecs, 2): which indices of basis_vecs you want to use\nvec_by_vec::Bool=true: whether you want to perform EMPCA one vector at a time (generally preffered) or all at once\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA.EMPCA-Tuple{AbstractVector{T} where T, Int64, AbstractMatrix{T} where T, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA.EMPCA","text":"EMPCA(μ, n_comp, data, weights; basis_vecs, scores, kwargs...)\n\nPerforms expectation-maximization principal component analysis (EMPCA) on data with n_comp basis vectors using weights as the weights. Pre-allocated arrays for basis_vecs, and scores, can be passed via keyword arguments.\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._empca_all_at_once!-NTuple{4, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._empca_all_at_once!","text":"_empca_all_at_once!(basis_vec, scores, data, weights; niter, kwargs...)\n\nPerforms in-place EMPCA, improving all basis vectors and scores with each iteration\n\nKeyword Arguments\n\nniter::Int=100: the amount of iterations used\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._empca_vec_by_vec!-NTuple{4, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._empca_vec_by_vec!","text":"_empca_vec_by_vec!(basis_vec, scores, data, weights; niter, kwargs...)\n\nPerforms in-place EMPCA, finishing one basis vector (and its scores) before moving onto the next\n\nKeyword Arguments\n\nniter::Int=100: the amount of iterations used\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._random_orthonormal!-Tuple{AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._random_orthonormal!","text":"_random_orthonormal!(A)\n\nFill A with orthonormal basis vectors\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._reorthogonalize!-Tuple{AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._reorthogonalize!","text":"_reorthogonalize!(basis_vec)\n\nModifies basis_vec to ensure all basis vectors are orthagonal and normalized\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._reorthogonalize_no_renorm!-Tuple{AbstractVector{T} where T, AbstractVector{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._reorthogonalize_no_renorm!","text":"_reorthogonalize!(basis_vec1, basis_vec2)\n\nModifies basis_vec1 to be orthagonal to basis_vec2 without normalizing\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._reorthogonalize_vec_i!-Tuple{AbstractMatrix{T} where T, Int64}","page":"Indices","title":"ExpectationMaximizationPCA._reorthogonalize_vec_i!","text":"_reorthogonalize!(basis_vec, i)\n\nModifies basis_vec[:, i] to ensure it orthagonal to basis_vec[:, 1:i-1] and normalized\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._solve-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractVector{T} where T, AbstractVector{T} where T}} where T<:Real","page":"Indices","title":"ExpectationMaximizationPCA._solve","text":"_solve(dm, data, w)\n\nGet optimal score(s) for modeling data with the basis vectors in the design matrix (dm) with weights (w) using generalized least squares (GLS)\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._solve_eigenvectors!-NTuple{4, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._solve_eigenvectors!","text":"_solve_eigenvectors!(basis_vecs, scores, data, weights)\n\nFill basis_vecs with those that optimally model data with the scores and weights (w)\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._solve_eigenvectors!-Tuple{AbstractVector{T} where T, AbstractVector{T} where T, AbstractMatrix{T} where T, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._solve_eigenvectors!","text":"_solve_eigenvectors!(basis_vec, scores, data, weights)\n\nFill basis_vec with the one that optimally model data with the scores and weights (w)\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._solve_scores!-NTuple{4, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._solve_scores!","text":"_solve_scores!(basis_vecs, scores, data, weights)\n\nFill scores with those that optimally model data with the basis_vecs and weights (w) using generalized least squares (GLS)\n\n\n\n\n\n","category":"method"},{"location":"indices/#ExpectationMaximizationPCA._solve_scores!-Tuple{AbstractVector{T} where T, AbstractVector{T} where T, AbstractMatrix{T} where T, AbstractMatrix{T} where T}","page":"Indices","title":"ExpectationMaximizationPCA._solve_scores!","text":"_solve_scores!(basis_vec, scores, data, weights)\n\nFill scores with those that optimally model data with the basis_vec and weights (w) using generalized least squares (GLS)\n\n\n\n\n\n","category":"method"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown, ExpectationMaximizationPCA\nMarkdown.parse_file(joinpath(pkgdir(ExpectationMaximizationPCA), \"LICENSE.md\"))","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = ExpectationMaximizationPCA","category":"page"},{"location":"#ExpectationMaximizationPCA.jl-Documentation","page":"Home","title":"ExpectationMaximizationPCA.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ExpectationMaximizationPCA.jl is a Julia rewrite of empca which provides Weighted Expectation Maximization PCA, an iterative method for solving PCA while properly weighting data.","category":"page"},{"location":"#Primary-function-definitions","page":"Home","title":"Primary function definitions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The ExpectationMaximizationPCA.EMPCA function is the primary function provided by ExpectationMaximizationPCA.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"ExpectationMaximizationPCA.EMPCA","category":"page"},{"location":"#ExpectationMaximizationPCA.EMPCA","page":"Home","title":"ExpectationMaximizationPCA.EMPCA","text":"EMPCA(μ, n_comp, data, weights; basis_vecs, scores, kwargs...)\n\nPerforms expectation-maximization principal component analysis (EMPCA) on data with n_comp basis vectors using weights as the weights. Pre-allocated arrays for basis_vecs, and scores, can be passed via keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"ExpectationMaximizationPCA.EMPCA!","category":"page"},{"location":"#ExpectationMaximizationPCA.EMPCA!","page":"Home","title":"ExpectationMaximizationPCA.EMPCA!","text":"EMPCA!(basis_vecs, scores, μ, data_tmp, weights; use_log, kwargs...)\n\nPerforms in-place (modifying basis_vecs, scores, and data_tmp) expectation-maximization principal component analysis (EMPCA) on data_tmp using weights as the weights.\n\nKeyword Arguments\n\nuse_log::false: whether you want to perform EMPCA on the log of data instead\ninds::AbstractUnitRange=axes(basis_vecs, 2): which indices of basis_vecs you want to use\nvec_by_vec::Bool=true: whether you want to perform EMPCA one vector at a time (generally preffered) or all at once\n\n\n\n\n\n","category":"function"},{"location":"#Citing-EMPCA","page":"Home","title":"Citing EMPCA","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use ExpectationMaximizationPCA.jl in an academic paper, please include a citation to S. Bailey 2012, PASP, 124, 1015 and optionally an acknowledgement such as:","category":"page"},{"location":"","page":"Home","title":"Home","text":"This work uses the Weighted EMPCA code by Stephen Bailey, available at https://github.com/sbailey/empca/","category":"page"},{"location":"","page":"Home","title":"Home","text":"BibTeX entry:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@ARTICLE{2012PASP..124.1015B,\n   author = {{Bailey}, S.},\n    title = \"{Principal Component Analysis with Noisy and/or Missing Data}\",\n  journal = {\\pasp},\narchivePrefix = \"arXiv\",\n   eprint = {1208.4122},\n primaryClass = \"astro-ph.IM\",\n keywords = {Data Analysis and Techniques},\n     year = 2012,\n    month = sep,\n   volume = 124,\n    pages = {1015-1023},\n      doi = {10.1086/668105},\n   adsurl = {http://adsabs.harvard.edu/abs/2012PASP..124.1015B},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}","category":"page"},{"location":"#Indices","page":"Home","title":"Indices","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of the package functions can be found here","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"indices.md\"]","category":"page"}]
}
